diff --git a/benchmarks/vectorized_random_translation.py b/benchmarks/vectorized_random_translation.py
index 2146d7c..cffad02 100644
--- a/benchmarks/vectorized_random_translation.py
+++ b/benchmarks/vectorized_random_translation.py
@@ -17,7 +17,7 @@ import time
 import matplotlib.pyplot as plt
 import numpy as np
 import tensorflow as tf
-from keras import backend
+from tf_keras import backend
 from tensorflow import keras
 
 from keras_cv.layers import RandomTranslation
diff --git a/benchmarks/vectorized_random_zoom.py b/benchmarks/vectorized_random_zoom.py
index b44919e..d7456cc 100644
--- a/benchmarks/vectorized_random_zoom.py
+++ b/benchmarks/vectorized_random_zoom.py
@@ -17,7 +17,7 @@ import time
 import matplotlib.pyplot as plt
 import numpy as np
 import tensorflow as tf
-from keras import backend
+from tf_keras import backend
 from tensorflow import keras
 
 from keras_cv.layers import RandomZoom
diff --git a/keras_cv/callbacks/pycoco_callback.py b/keras_cv/callbacks/pycoco_callback.py
index 6a9a688..3a7e77f 100644
--- a/keras_cv/callbacks/pycoco_callback.py
+++ b/keras_cv/callbacks/pycoco_callback.py
@@ -12,7 +12,7 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import tensorflow as tf
-from keras.callbacks import Callback
+from tf_keras.callbacks import Callback
 
 from keras_cv import bounding_box
 from keras_cv.metrics.coco import compute_pycoco_metrics
diff --git a/keras_cv/callbacks/waymo_evaluation_callback.py b/keras_cv/callbacks/waymo_evaluation_callback.py
index 6c13ca7..2dff3ea 100644
--- a/keras_cv/callbacks/waymo_evaluation_callback.py
+++ b/keras_cv/callbacks/waymo_evaluation_callback.py
@@ -12,7 +12,7 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import tensorflow as tf
-from keras.callbacks import Callback
+from tf_keras.callbacks import Callback
 
 from keras_cv.utils import assert_waymo_open_dataset_installed
 
diff --git a/keras_cv/layers/fusedmbconv.py b/keras_cv/layers/fusedmbconv.py
index b03543f..64240d9 100644
--- a/keras_cv/layers/fusedmbconv.py
+++ b/keras_cv/layers/fusedmbconv.py
@@ -13,7 +13,7 @@
 # limitations under the License.
 
 
-from keras import backend
+from tf_keras import backend
 from tensorflow import keras
 from tensorflow.keras import layers
 
diff --git a/keras_cv/layers/mbconv.py b/keras_cv/layers/mbconv.py
index c4991a1..7f10b4c 100644
--- a/keras_cv/layers/mbconv.py
+++ b/keras_cv/layers/mbconv.py
@@ -13,7 +13,7 @@
 # limitations under the License.
 
 
-from keras import backend
+from tf_keras import backend
 from tensorflow import keras
 from tensorflow.keras import layers
 
diff --git a/keras_cv/layers/preprocessing/random_zoom.py b/keras_cv/layers/preprocessing/random_zoom.py
index f3dfced..b158369 100644
--- a/keras_cv/layers/preprocessing/random_zoom.py
+++ b/keras_cv/layers/preprocessing/random_zoom.py
@@ -14,7 +14,7 @@
 
 
 import tensorflow as tf
-from keras import backend
+from tf_keras import backend
 from tensorflow import keras
 
 from keras_cv.layers.preprocessing.vectorized_base_image_augmentation_layer import (  # noqa: E501
diff --git a/keras_cv/models/classification/image_classifier.py b/keras_cv/models/classification/image_classifier.py
index 6d34f50..5b84bfa 100644
--- a/keras_cv/models/classification/image_classifier.py
+++ b/keras_cv/models/classification/image_classifier.py
@@ -15,7 +15,7 @@
 
 import copy
 
-from keras import layers
+from tf_keras import layers
 from tensorflow import keras
 
 from keras_cv.models.backbones.backbone_presets import backbone_presets
diff --git a/keras_cv/models/legacy/efficientnet_lite.py b/keras_cv/models/legacy/efficientnet_lite.py
index a2ae8d3..826a7e6 100644
--- a/keras_cv/models/legacy/efficientnet_lite.py
+++ b/keras_cv/models/legacy/efficientnet_lite.py
@@ -25,8 +25,8 @@ import copy
 import math
 
 import tensorflow as tf
-from keras import backend
-from keras import layers
+from tf_keras import backend
+from tf_keras import layers
 from tensorflow import keras
 
 from keras_cv.models.legacy import utils
diff --git a/keras_cv/models/legacy/utils.py b/keras_cv/models/legacy/utils.py
index ba3e852..cd74f4b 100644
--- a/keras_cv/models/legacy/utils.py
+++ b/keras_cv/models/legacy/utils.py
@@ -14,7 +14,7 @@
 # ==============================================================================
 """Utility functions for models"""
 
-from keras import layers
+from tf_keras import layers
 from tensorflow import keras
 
 
diff --git a/keras_cv/models/legacy/utils_test.py b/keras_cv/models/legacy/utils_test.py
index cbd1bbc..e0aa448 100644
--- a/keras_cv/models/legacy/utils_test.py
+++ b/keras_cv/models/legacy/utils_test.py
@@ -14,7 +14,7 @@
 """Tests for KerasCV model utils."""
 
 import tensorflow as tf
-from keras import layers
+from tf_keras import layers
 from tensorflow import keras
 
 from keras_cv.models.legacy import utils
diff --git a/keras_cv/models/legacy/weights.py b/keras_cv/models/legacy/weights.py
index fc99606..d21a6b9 100644
--- a/keras_cv/models/legacy/weights.py
+++ b/keras_cv/models/legacy/weights.py
@@ -11,7 +11,7 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 import tensorflow as tf
-from keras import utils
+from tf_keras import utils
 
 
 def parse_weights(weights, include_top, model_type):
diff --git a/keras_cv/models/object_detection/predict_utils.py b/keras_cv/models/object_detection/predict_utils.py
index 8eb6e10..48fb78d 100644
--- a/keras_cv/models/object_detection/predict_utils.py
+++ b/keras_cv/models/object_detection/predict_utils.py
@@ -15,13 +15,13 @@
 import tensorflow as tf
 
 try:
-    from keras.src.engine.training import _minimum_control_deps
-    from keras.src.engine.training import reduce_per_replica
-    from keras.src.utils import tf_utils
+    from tf_keras.src.engine.training import _minimum_control_deps
+    from tf_keras.src.engine.training import reduce_per_replica
+    from tf_keras.src.utils import tf_utils
 except ImportError:
-    from keras.engine.training import _minimum_control_deps
-    from keras.engine.training import reduce_per_replica
-    from keras.utils import tf_utils
+    from tf_keras.engine.training import _minimum_control_deps
+    from tf_keras.engine.training import reduce_per_replica
+    from tf_keras.utils import tf_utils
 
 
 def make_predict_function(model, force=False):
diff --git a/keras_cv/models/object_detection/yolo_v8/yolo_v8_backbone.py b/keras_cv/models/object_detection/yolo_v8/yolo_v8_backbone.py
index 89e2763..9910ac9 100644
--- a/keras_cv/models/object_detection/yolo_v8/yolo_v8_backbone.py
+++ b/keras_cv/models/object_detection/yolo_v8/yolo_v8_backbone.py
@@ -14,7 +14,7 @@
 import copy
 
 import tensorflow as tf
-from keras import layers
+from tf_keras import layers
 from tensorflow import keras
 
 from keras_cv.models import utils
diff --git a/keras_cv/models/object_detection/yolo_v8/yolo_v8_detector.py b/keras_cv/models/object_detection/yolo_v8/yolo_v8_detector.py
index 360d01c..7db9974 100644
--- a/keras_cv/models/object_detection/yolo_v8/yolo_v8_detector.py
+++ b/keras_cv/models/object_detection/yolo_v8/yolo_v8_detector.py
@@ -15,7 +15,7 @@ import copy
 import warnings
 
 import tensorflow as tf
-from keras import layers
+from tf_keras import layers
 from tensorflow import keras
 
 import keras_cv
diff --git a/keras_cv/models/object_detection/yolo_v8/yolo_v8_layers.py b/keras_cv/models/object_detection/yolo_v8/yolo_v8_layers.py
index ba9c095..effae68 100644
--- a/keras_cv/models/object_detection/yolo_v8/yolo_v8_layers.py
+++ b/keras_cv/models/object_detection/yolo_v8/yolo_v8_layers.py
@@ -12,7 +12,7 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import tensorflow as tf
-from keras import layers
+from tf_keras import layers
 
 BATCH_NORM_EPSILON = 1e-3
 BATCH_NORM_MOMENTUM = 0.97
diff --git a/keras_cv/models/stable_diffusion/__internal__/layers/attention_block.py b/keras_cv/models/stable_diffusion/__internal__/layers/attention_block.py
index e7e1896..21fba0c 100644
--- a/keras_cv/models/stable_diffusion/__internal__/layers/attention_block.py
+++ b/keras_cv/models/stable_diffusion/__internal__/layers/attention_block.py
@@ -14,6 +14,12 @@
 
 import tensorflow as tf
 from tensorflow import keras
+try:
+    import intel_extension_for_tensorflow as itex
+    keras.layers.GroupNormalization = itex.ops.GroupNormalization
+except:
+    pass
+    
 
 from keras_cv.models.stable_diffusion.__internal__.layers.padded_conv2d import (
     PaddedConv2D,
diff --git a/keras_cv/models/stable_diffusion/__internal__/layers/resnet_block.py b/keras_cv/models/stable_diffusion/__internal__/layers/resnet_block.py
index 29aeaaa..11d4be6 100644
--- a/keras_cv/models/stable_diffusion/__internal__/layers/resnet_block.py
+++ b/keras_cv/models/stable_diffusion/__internal__/layers/resnet_block.py
@@ -13,6 +13,13 @@
 # limitations under the License.
 
 from tensorflow import keras
+try:
+    import intel_extension_for_tensorflow as itex
+    keras.layers.GroupNormalization = itex.ops.GroupNormalization
+except:
+    pass
+    
+    
 
 from keras_cv.models.stable_diffusion.__internal__.layers.padded_conv2d import (
     PaddedConv2D,
diff --git a/keras_cv/models/stable_diffusion/decoder.py b/keras_cv/models/stable_diffusion/decoder.py
index fe619d3..ccc4b5b 100644
--- a/keras_cv/models/stable_diffusion/decoder.py
+++ b/keras_cv/models/stable_diffusion/decoder.py
@@ -13,6 +13,12 @@
 # limitations under the License.
 
 from tensorflow import keras
+try:
+    import intel_extension_for_tensorflow as itex
+    keras.layers.GroupNormalization = itex.ops.GroupNormalization
+except:
+    pass
+    
 
 from keras_cv.models.stable_diffusion.__internal__.layers.attention_block import (  # noqa: E501
     AttentionBlock,
diff --git a/keras_cv/models/stable_diffusion/diffusion_model.py b/keras_cv/models/stable_diffusion/diffusion_model.py
index 25b5241..db75e97 100644
--- a/keras_cv/models/stable_diffusion/diffusion_model.py
+++ b/keras_cv/models/stable_diffusion/diffusion_model.py
@@ -14,7 +14,14 @@
 
 import tensorflow as tf
 from tensorflow import keras
-
+try:
+    import intel_extension_for_tensorflow as itex
+    keras.layers.GroupNormalization = itex.ops.GroupNormalization
+    keras.layers.LayerNormalization = itex.ops.LayerNormalization
+except:
+    pass
+    
+    
 from keras_cv.models.stable_diffusion.__internal__.layers.padded_conv2d import (
     PaddedConv2D,
 )
@@ -302,6 +309,26 @@ class CrossAttention(keras.layers.Layer):
         self.num_heads = num_heads
         self.head_size = head_size
         self.out_proj = keras.layers.Dense(num_heads * head_size)
+        
+    def naive_scaled_dot_product_attention(self, query, key, value):
+        i_dtype = query.dtype
+        atten_scores = tf.matmul(query, key, transpose_b=True)
+        atten_scores = tf.multiply(atten_scores, tf.cast(self.scale, i_dtype))
+        atten_probs = tf.nn.softmax(atten_scores)
+        # `atten_output` = [B, N, F, H]
+        atten_output = tf.matmul(atten_probs, value)
+        # `atten_output` = [B, F, N, H]
+        atten_output  = tf.transpose(a=atten_output, perm=[0, 2, 1, 3]) 
+        return atten_output
+
+
+    def sdp(self, q, k, v):
+        try:
+            from intel_extension_for_tensorflow.python.ops.multi_head_attention import scaled_dot_product_attention
+            output = scaled_dot_product_attention(q, k, v, use_fast_attention=True, is_training=False)
+        except ImportError:
+            output = self.naive_scaled_dot_product_attention(q, k, v)
+        return output
 
     def call(self, inputs):
         inputs, context = inputs
@@ -316,17 +343,10 @@ class CrossAttention(keras.layers.Layer):
         )
 
         q = tf.transpose(q, (0, 2, 1, 3))  # (bs, num_heads, time, head_size)
-        k = tf.transpose(k, (0, 2, 3, 1))  # (bs, num_heads, head_size, time)
+        k = tf.transpose(k, (0, 2, 1, 3))  # (bs, num_heads, head_size, time)
         v = tf.transpose(v, (0, 2, 1, 3))  # (bs, num_heads, time, head_size)
 
-        score = td_dot(q, k) * self.scale
-        weights = keras.activations.softmax(
-            score
-        )  # (bs, num_heads, time, time)
-        attn = td_dot(weights, v)
-        attn = tf.transpose(
-            attn, (0, 2, 1, 3)
-        )  # (bs, time, num_heads, head_size)
+        attn = self.sdp(q, k, v)
         out = tf.reshape(
             attn, (-1, inputs.shape[1], self.num_heads * self.head_size)
         )
@@ -352,10 +372,11 @@ class GEGLU(keras.layers.Layer):
     def call(self, inputs):
         x = self.dense(inputs)
         x, gate = x[..., : self.output_dim], x[..., self.output_dim :]
-        tanh_res = keras.activations.tanh(
-            gate * 0.7978845608 * (1 + 0.044715 * (gate**2))
-        )
-        return x * 0.5 * gate * (1 + tanh_res)
+        # tanh_res = keras.activations.tanh(
+        #     gate * 0.7978845608 * (1 + 0.044715 * (gate**2))
+        # )
+        # return x * 0.5 * gate * (1 + tanh_res)
+        return x * tf.keras.activations.gelu(gate, approximate=True)
 
 
 def td_dot(a, b):
diff --git a/keras_cv/models/stable_diffusion/image_encoder.py b/keras_cv/models/stable_diffusion/image_encoder.py
index 614b11d..8212389 100644
--- a/keras_cv/models/stable_diffusion/image_encoder.py
+++ b/keras_cv/models/stable_diffusion/image_encoder.py
@@ -13,6 +13,12 @@
 # limitations under the License.
 
 from tensorflow import keras
+try:
+    import intel_extension_for_tensorflow as itex
+    keras.layers.GroupNormalization = itex.ops.GroupNormalization
+except:
+    pass
+
 
 from keras_cv.models.stable_diffusion.__internal__.layers.attention_block import (  # noqa: E501
     AttentionBlock,
diff --git a/keras_cv/models/stable_diffusion/stable_diffusion.py b/keras_cv/models/stable_diffusion/stable_diffusion.py
index 5ef7471..38f9ee6 100644
--- a/keras_cv/models/stable_diffusion/stable_diffusion.py
+++ b/keras_cv/models/stable_diffusion/stable_diffusion.py
@@ -29,7 +29,8 @@ import math
 import numpy as np
 import tensorflow as tf
 from tensorflow import keras
-
+from tf_keras import backend as K
+import os
 from keras_cv.models.stable_diffusion.clip_tokenizer import SimpleTokenizer
 from keras_cv.models.stable_diffusion.constants import _ALPHAS_CUMPROD
 from keras_cv.models.stable_diffusion.constants import _UNCONDITIONAL_TOKENS
@@ -51,6 +52,7 @@ class StableDiffusionBase:
         img_height=512,
         img_width=512,
         jit_compile=False,
+        precision="fp32",
     ):
         # UNet requires multiples of 2**7 = 128
         img_height = round(img_height / 128) * 128
@@ -66,6 +68,7 @@ class StableDiffusionBase:
         self._tokenizer = None
 
         self.jit_compile = jit_compile
+        self.to_fp16 = (precision == "fp16")
 
     def text_to_image(
         self,
@@ -76,6 +79,9 @@ class StableDiffusionBase:
         unconditional_guidance_scale=7.5,
         seed=None,
     ):
+        if self.to_fp16:
+            K.set_floatx('float16')
+
         encoded_text = self.encode_text(prompt)
 
         return self.generate_image(
@@ -207,18 +213,21 @@ class StableDiffusionBase:
 
         # Iterative reverse diffusion stage
         timesteps = tf.range(1, 1000, 1000 // num_steps)
+        t_embs_lst = self._get_timesteps_embedding(timesteps, batch_size)
+        contexts = tf.concat((unconditional_context, context), 0)
+
         alphas, alphas_prev = self._get_initial_alphas(timesteps)
         progbar = keras.utils.Progbar(len(timesteps))
         iteration = 0
         for index, timestep in list(enumerate(timesteps))[::-1]:
             latent_prev = latent  # Set aside the previous latent vector
-            t_emb = self._get_timestep_embedding(timestep, batch_size)
-            unconditional_latent = self.diffusion_model.predict_on_batch(
-                [latent, t_emb, unconditional_context]
-            )
-            latent = self.diffusion_model.predict_on_batch(
-                [latent, t_emb, context]
-            )
+            latents = tf.concat((latent, latent), 0)
+            t_embs = t_embs_lst[index]
+
+            pred_latent = self.diffusion_model.predict_on_batch(
+                [latents, t_embs, contexts])
+            unconditional_latent, latent = tf.split(pred_latent, 2)
+
             latent = unconditional_latent + unconditional_guidance_scale * (
                 latent - unconditional_latent
             )
@@ -304,6 +313,23 @@ class StableDiffusionBase:
             self._tokenizer = SimpleTokenizer()
         return self._tokenizer
 
+    def _get_timesteps_embedding(
+        self, timesteps, batch_size, dim=320, max_period=10000
+    ):
+        half = dim // 2
+        freqs = tf.math.exp(
+            -math.log(max_period) * tf.range(0, half, dtype=tf.float32) / half
+        )
+        # timesteps shape: [num_steps]
+        args = tf.cast(tf.reshape(timesteps, [-1, 1]), dtype=tf.float32) * freqs
+        # embeddings shape:(steps, half)
+        embeddings = tf.concat([tf.math.cos(args), tf.math.sin(args)], axis=1)
+        embeddings = tf.expand_dims(embeddings, axis=1)
+        if self.to_fp16:
+            embeddings = tf.cast(embeddings, tf.float16)
+        #  2 is to concatenate the embedding of two forward pass
+        return tf.repeat(embeddings, batch_size * 2, axis=1)
+
     def _get_timestep_embedding(
         self, timestep, batch_size, dim=320, max_period=10000
     ):
@@ -314,6 +340,8 @@ class StableDiffusionBase:
         args = tf.convert_to_tensor([timestep], dtype=tf.float32) * freqs
         embedding = tf.concat([tf.math.cos(args), tf.math.sin(args)], 0)
         embedding = tf.reshape(embedding, [1, -1])
+        if self.to_fp16:
+            embedding = tf.cast(embedding, tf.float16)
         return tf.repeat(embedding, batch_size, axis=0)
 
     def _get_initial_alphas(self, timesteps):
@@ -324,14 +352,25 @@ class StableDiffusionBase:
 
     def _get_initial_diffusion_noise(self, batch_size, seed):
         if seed is not None:
-            return tf.random.stateless_normal(
-                (batch_size, self.img_height // 8, self.img_width // 8, 4),
-                seed=[seed, seed],
-            )
+            if self.to_fp16:
+                return tf.random.stateless_normal(
+                    (batch_size, self.img_height // 8, self.img_width // 8, 4),
+                    seed=[seed, seed], dtype=tf.float16
+                )
+            else:
+                return tf.random.stateless_normal(
+                    (batch_size, self.img_height // 8, self.img_width // 8, 4),
+                    seed=[seed, seed],
+                )
         else:
-            return tf.random.normal(
-                (batch_size, self.img_height // 8, self.img_width // 8, 4)
-            )
+            if self.to_fp16:
+                return tf.random.normal(
+                        (batch_size, self.img_height // 8, self.img_width // 8, 4), dtype=tf.float16
+                    )
+            else:
+                return tf.random.normal(
+                    (batch_size, self.img_height // 8, self.img_width // 8, 4)
+                )
 
     @staticmethod
     def _get_pos_ids():
@@ -390,8 +429,9 @@ class StableDiffusion(StableDiffusionBase):
         img_height=512,
         img_width=512,
         jit_compile=False,
+        precision="fp32",
     ):
-        super().__init__(img_height, img_width, jit_compile)
+        super().__init__(img_height, img_width, jit_compile, precision)
         print(
             "By using this model checkpoint, you acknowledge that its usage is "
             "subject to the terms of the CreativeML Open RAIL-M license at "
@@ -475,8 +515,9 @@ class StableDiffusionV2(StableDiffusionBase):
         img_height=512,
         img_width=512,
         jit_compile=False,
+        precision="fp32",
     ):
-        super().__init__(img_height, img_width, jit_compile)
+        super().__init__(img_height, img_width, jit_compile, precision)
         print(
             "By using this model checkpoint, you acknowledge that its usage is "
             "subject to the terms of the CreativeML Open RAIL++-M license at "
diff --git a/keras_cv/models/utils.py b/keras_cv/models/utils.py
index 44776a2..c163beb 100644
--- a/keras_cv/models/utils.py
+++ b/keras_cv/models/utils.py
@@ -14,8 +14,8 @@
 # ==============================================================================
 """Utility functions for models"""
 
-from keras import backend
-from keras import layers
+from tf_keras import backend
+from tf_keras import layers
 from tensorflow import keras
 
 
diff --git a/keras_cv/models/utils_test.py b/keras_cv/models/utils_test.py
index 5f5efba..a41a4bf 100644
--- a/keras_cv/models/utils_test.py
+++ b/keras_cv/models/utils_test.py
@@ -14,7 +14,7 @@
 """Tests for KerasCV model utils."""
 
 import tensorflow as tf
-from keras import layers
+from tf_keras import layers
 
 from keras_cv.models import utils
 
diff --git a/shell/count_preset_params.py b/shell/count_preset_params.py
index ffe05b3..e22fe9d 100644
--- a/shell/count_preset_params.py
+++ b/shell/count_preset_params.py
@@ -24,7 +24,7 @@ import inspect
 
 from absl import app
 from absl import flags
-from keras.utils.layer_utils import count_params
+from tf_keras.utils.layer_utils import count_params
 
 import keras_cv
 
